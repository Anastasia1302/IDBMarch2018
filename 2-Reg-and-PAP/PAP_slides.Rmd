---
title: "Registration, Pre-Analysis Plans and Reporting Guidelines"
author: "| Fernando Hoces de la Guardia\n| BITSS   \n| -\n| Slides at <https://goo.gl/aBQ3LR>\n"
date: "Inter-American Development Bank Workshop, March 2018"
output:
  beamer_presentation:
    fig_caption: no
    slide_level: 2
  slidy_presentation: default
subtitle: Introduction, Hands-on with the Open Science Framework (OSF) and AEA Registry
editor_options:
  chunk_output_type: console
---

# Let's Start With a Little Experiment!

## Explanation to participants

- \Large{Read and complete the sheet. Do not look at others sheets.}

\bigskip 

- \Large{Go to the website bellow and complete with your answers.}

\begin{center}
\LARGE{https://goo.gl/aj8W61}  
\end{center}

##  

\begin{center}
{\LARGE Thank you for participating} \\
We will refer back to this exercise in the hands-on part of the presentation.
\end{center}

## Outline
\tableofcontents

# Registration & PAP: What

## What is a Registration and a PAP? (Clark 2017)  

### Registration: 
Title, country, status, keyword,
abstract, start and end dates, outcomes, intervention,
basic research design, whether treatment clustered, IRB
information.  

### PAP: 
Detailed description of research design and
data analysis plans, submitted to a registry BEFORE
looking at the data.

# Registration & PAP: Why

## Why Do We Need Registration? Publication Bias Across Social Science
 \centerline{\includegraphics[height=3in]{Tess.png}}

## Why Do We Need PAPs? The Threat of P-Hacking
**Casey et al. 2012**  
![](GoBifo1.PNG)

## Why Do We Need PAPs? The Extension of P-Hacking 
**Athey 2018**  
![](athey.PNG)

## Why Do We Need PAPs? The Practice of P-Hacking 
**BuzzFeed 2018!**  
![](phacking.PNG)

## Why? Null Results Increase After Requiring Registrations
**Kaplan & Irvin**  
![](plosone.PNG)

## Why Do We Need PAPs? The Social Planner View (Haushofer, 2017)

**Benefits:**  
1. Improves transparency: clear ex-ante what the researcher planned  
2. Reduces false positives: fewer forking paths, less p-hacking  
3. Reduces the file drawer problem; others can ask what happened to your project. 

\pause

**Costs:**    
1. Time cost. I don’t think this is very large, see below.  
2. Stifles exploratory work. I don’t think this is true, see below.  
3. Pre-specifying the wrong analyses (ex ante or ex post). This is potentially serious.   
\pause

**Reducing costs:**    
1. Time cost: make the PAP your methods section later.  
2. Exploratory work: data mine to your heart’s delight! Just be honest about it.  
3. Pre-specifying the wrong analyses: Be honest about your thought process and hope for sensible readers/referees.  


## Why write one? Individual View (Haushofer, 2017+)
Benefits  
1. Signals dedication to honesty and rigor.   
2. Now you can get in-principle acceptance to a good PAP (JDE).  

Costs  
1. Journals (until very recently) care mainly about interesting findings than PAPs. On the margin, PAPs not very helpful.  
2. More difficult with a PAP to make serendipitous discoveries the main story. That’s as it should be.   


# Registration & PAP: How


## Similarities between Registration and PAP?

 - Time stamped document, public (or to be published in a specified date), that describes a prospective study. 
 - Both go in same registries:
    - Medicine: clinicaltrial.gov
    - Social Science (RCTs): socialscienceregistry.org (AEA)
    - Social Science (Observational in dev. countries): [RIDIE (3ie)](http://www.3ieimpact.org/en/evaluation/ridie/)
    - All disciplines and methods: osf.io


## Difference between Registration and PAP?

  - Key difference is the amount of detail/effort. 
  - Registration: very easy, goal is to track publication bias. 
  - PAP: much more detail required. Similar to grant application/work plan.
 - It is more a matter of degree. 
 - For our hands-on exercise we will be doing a quick registration.



## Back to our little experiment: Explanation to researchers

- You  participated in (highly simplified) version of **The Ultimatum Game**

- The goal of the UG is to measure attitudes about fairness and/or expectations about (econ) rational behavior. 

- Our little experiment was trying to measure if the responses to the UG can be anchored by a completely irrelevant number: **The ID number at the beginning of your sheet!**

## Explanation to researchers

- Treatment was receiving an ID number between 960 and 999.
- Control receive an ID number between 10 and 49.

- Outcome: Offer made in the UG

- For the , you can use this experiment, or work with your own paper/project. 

## Hands-on Registration.
Based on a project of your own, or on our little experiment:  

 - Create a draft of using [Open Science Framework](osf.io) at [osf.io](osf.io):  
     - Open format
     - AsPredicted (will work with this one)
  
 - Explore [AEA Registry](www.socialscienceregistry.org) at [www.socialscienceregistry.org](www.socialscienceregistry.org)

## Registration of our Little Experiment 
Using Aspredicted format:    
\pause  
 - **Research question:** \pause  Does exposure to a large number increases the offer made in the ultimatum game?  
\pause  
 - **Dependent variable:** \pause  Amount offered in the ultimatum game.   
\pause  
 - **Treatment:**  \pause  Participant will be randomly assigned a large number ([960, 999]) or a small number ([10, 49]) to be read and remember, before reading the ultimatum game question.   
\pause    
 - **Analyses:** \pause  OLS regression of amount offer as dependant variable and treatment as regressor.     
\pause    
 - **Outliers and Exclusions:** \pause  Will exclude participants with missing information in any field. Amounts beyond plausible values (eg offers above max dollar value) will be will be top-coded.   
\pause  
 - **Sample size:** \pause  We will define our sample by the number of participants in the workshop.   

## How to do a PAP? Glennerster & Takavarasha Suggestions  

Report:  

 - The main outcome measures.  
 - Which outcome measures are primary and which are secondary.  
 - The precise composition of any families that will be used for mean effects analysis.  
 - The subgroups that will be analyzed.  
 - The direction of expected impact if we want to use a one-sided test.   
 - The primary specification to be used for the analysis.  



## How to do a PAP? McKenzie Suggestions
[World Bank Development Impact Blog](http://blogs.worldbank.org/impactevaluations/a-pre-analysis-plan-checklist)

 - Description of the sample to be used in the study  
 - Key data sources  
 - Hypotheses to be tested throughout the causal chain  
 - Specify how variables will be constructed  
 - Specify the treatment effect equation to be estimated  
 - What is the plan for how to deal with multiple outcomes and multiple
  hypothesis testing?  
 - Procedures to be used for addressing survey attrition  
 - How will the study deal with outcomes with limited variation?  
 - If you are going to be testing a model, include the model  
 - Remember to archive it  

## OSF registration format for Pre-reg Challenge  
 ![](reg2.png){ width=50% }    
   
 ![](reg1.png)  
 
 
## Register Reports at the JDE.  

 ![](RR.png)  
[Guidelines](https://www.elsevier.com/__data/promis_misc/JDE_RR_Author_Guidelines.pdf) and [Checklist](https://docs.google.com/spreadsheets/d/1zhG3AxOJIB7H1m4-S0jwMN1cQKNVsLomsxktEDVrbP8/edit#gid=1835444640)

<!--
## Summary ????
-->

![](cost_and_ben.png)

## Final Considerations for Registrations & PAPs

### Time dimention. 
 - Both PAPs and Registrations should be submitted to a public registry *before* looking at the *entire dataset*.

 - A broadly defined registration should not change much so the earlier the better. 
 
 - A precise PAP need as much information as possible. Ok to look at data, as long as can prove lack of access either treatment or outcome variable.   
 
### Deviations. 
 - It is completely fine to deviate from the original PAP. Just label it properly. 
 - Really good example of how to handle deviations: Green's SOPs ([Article](https://www.stat.berkeley.edu/~winston/sop-safety-net.pdf), [SOP](http://alexandercoppock.com/Green-Lab-SOP/Green_Lab_SOP.html))

 
# Reporting Guidelines

<!--
Review Smart project by Gabe Lenz
-->

## Why Do We Need Reporting Guidelines?  
Defines minimal set of elements required in a scientific paper. 
Helps with:  
 - Structured PAPs  
 - Replicability    
 - Meta-analysis (see [aidgrade.org](http://www.aidgrade.org/get-data))   
 
Great discussion of standarized reporting by David Evans on the World Bank blog [here](https://blogs.worldbank.org/impactevaluations/if-you-want-your-study-included-systematic-review-what-you-should-report).

 
## How to follow Reporting Guidelines  
 - CONSORT Guidelines & EQUATOR network.
 - Recent [APA guidelines](http://psycnet.apa.org/fulltext/2018-00750-002.pdf).
 - JDE [author guidelines](https://www.bitss.org/wp-content/uploads/2018/03/JDE_RR_Author_Guidelines.pdf) for register reports (with a great [checklist here](https://docs.google.com/spreadsheets/d/1zhG3AxOJIB7H1m4-S0jwMN1cQKNVsLomsxktEDVrbP8/edit#gid=1835444640)). 
 
## CONSORT Guidelines & EQUATOR network.
![](Consort1.png)


## CONSORT Guidelines & EQUATOR network.
![](Consort2.png)  
EQUATOR Network: website containing more than 300 other guidelines.
