---
title: "Reproducible Workflow: Coding Strategies and Software [75mins]"
subtitle: "Introduction, Hands-on with Version Control (Github) and Dynamic Documents (RMarkdown)"  
author: "| Fernando Hoces de la Guardia\n| BITSS   \n| -\n| Slides at <https://goo.gl/aBQ3LR>\n"
date: "Inter-American Development Bank Workshop, March 2018"
output: 
  beamer_presentation:
    slide_level: 2
---
# File Management & Coding Suggestions (Christensen et al, 2018) [15 mins]
## File Management [5 mins] 
![](files.png)

## Organizing Principles

### 1 - Use code (scripts), don't work by hand (GUI's or comand line).
### 2 - Consider not saving statistical output, and just saving the code and data that generates it.
### 3 - Reproducibility. Minimum: machine (laptop) independence. Ideal: analyst indepence. 

## Coding Suggestions [10 mins]

<!--
1)	Make sure that your script files are self-contained. That is, don't write a program that only works if you run a group of other files previously in a specific order and then leave things hanging in a certain precarious way. You should be able to run intermediate steps of the workflow without disrupting things downstream.  
-->  
1) Include tests in your code.   
<!-- 
This can alert you if output ever changes unexpectedly. For example, if merging intermediate datasets and dropping unmatched observations, you could write code to throw an error and alert you if the number of observations changes. (See the Stata example below.)
-->
2) You can never comment your code too much.   
<!-- Comments should truly explain what the code is doing rather than merely transliterating: it is more useful to describe x<-1 with "initialize the population count to 1" than "set x equal to 1." Comments should also be checked to make sure they don't go out of date and convey inaccurate information.
--> 
3) Indent your code.   
4) Once posted, any changes at all require a new file name. Or a version control system in place.  
5) Separate your data cleaning and analysis files
<!-- don't make any new variables that need saving (or will be used by multiple analysis files) in an analysis file. It is far better to only create a variable once so you know that it is identical when used in different analysis files.
-->  
6) Never name a file "final" because it won't be.
<!-- , and why do you want to tempt fate? Instead, add a date and author initials or version number.
-->  
7) Name binary variables "male" instead of "gender," (1=Male and 0=Not)

8) Don't leave clutter around-delete temporary or unnecessary intermediate objects. 
<!-- You can use a prefix such as x_ or temp_ so you know which files or variables can easily be deleted later. Stata also has the tempfile and tempvar functionality.  
-->  
9) Every variable should have a label. 

10) Use relative directory paths (such as "./Data" and not "C:/Users/Fernando/Documents/Project/Data") 

## Coding Suggestions: Stata-specific
1)	Accurately and concisely capture missing values. (`.` and `.a-.z`)
<!-- There are multiple reasons that a value might be blank. To fully convey this, use the full set of missing values available to you (".a"-".z", not exclusively ".") in order to distinguish between "don't know" and "didn't ask," or other distinct reasons for missing data. 
-->
2)	Make sure code always produces the same result, and that merging and sorting is reproducible. `duplicates report; isid; sort, stable`  

3)	Run simple tests to alert yourself when results change. Example:

        count if _merge!=3
        if r(N)!=74 {
        display "Unmatched observations changed!"
        there is an error here
        } 
4)	Don't use abbreviations for variables or commands.
5)	Use global macros to define directory paths so collaborators can readily work across different computers.
6)	Use local macros for varlists.

## Coding Suggestions: Stata-specific
7)	Use computer-stored versions of numerical output (eg `r(mean)`). Use `return list` and `ereturn list`
8)	If you have a master .do file that calls other .do files, which each have their own .log file capturing output, you can run multiple log files at the same time (so you end up with a master .log file)
9)	Use the `label data` and `notes`.
10)	Use the `notes` command for variables as well for identifying information that is too long for the variable label.
 
11)	Validate data sources to ensure consistency. Use `datasignature` on auto data set (`sysuse auto.dta`, then `datasignature set` should give you this number: `74:12(71728):3831085005:1395876116`) 
12)	Use value labels for all categorical variables. `numlabel [lblname-list], add command.`  
13)	Don't use capital letters in variable names.
14)	Make your files as non-proprietary as possible (use the `saveold` command) 


# Version Control [30 mins]

## Problem to avoid
![http://www.phdcomics.com/comics/archive/phd101212s.gif](http://www.phdcomics.com/comics/archive/phd101212s.gif)

## Managing expectations
![Git xkcd comic](https://imgs.xkcd.com/comics/git.png)


# Dynamic Documents [30 mins]



## Dynamic Documents For Computational Reproducibility
- Based on principles of *literate programming* aims at combining code and paper in one single document 
- Best framework to achieve the holy grail of **one-click reproducible workflow**
- Best two current implementations: `RMarkdown (R)` & `Jupyter (Python)`. `Stata` is catching up (more at the end)

## Currently code and narrative components live in separate universes 
![](./Two universes.png)   


## Dynamic Documents: integrate the two universes!  
![](./One universe.png)

  
## Dynamic Documents: A Recipe  

- 1 simple language that can combine text and code: `Markdown` 
- 1 statistical package to do the analysis (`R`, `Python`, `3S's?`)
- 1 machinery to combine analysis and text to create a single output: `Pandoc`
- [Optional-but-not-really] 1 program to bring all the elements together: RStudio/RMarkdown, Jupyter

## Markdown laguange/syntax in 60 seconds
![](./RStudioCS.png)

# One Type of Dynamic Document: R Markdown

## For our excercise: R Markdown  

- `R`: **open source** programming language design for statistical analysis.   
- RStudio: free software that provides and Integrated Development Environment (IDE)  
- RStudio combines all together: R + Markdown + Pandoc to produce multiple outputs
![](http://rmarkdown.rstudio.com/images/RMarkdownFlow.png)  


## R Markdown  
![](http://rmarkdown.rstudio.com/images/RMarkdownOutputFormats.png)

## Basic Structure

- A header
- Text
- Code: inline and chunks

## Basic Structure: Header



```{r smpl yml, eval=FALSE, echo=TRUE}
---
title: "Sample Paper"
author: "Fernando Hoces de la Guardia"
output: html_document
---
```  




## Basic Structure: Body of Text

```{r smpl_yml1, eval=FALSE, echo=TRUE}
---
header
---
```

This is where you write your paper. Nothing much to add. You can check Markdown [syntax here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf). And it can use can type equations using LaTex syntax!

## Basic Structure: Code Chunks and Inline

```{r smpl_yml2, eval=FALSE, echo=TRUE}
---
header
---
```

Body of text. 


To begin a piece of code ("code chunk"). Enclose them in the following expression (Ctrl/Cmd + shift/optn + i) 

````
```{r, eval=TRUE}`r ''`
here goes the code
```
````

To write inline use only one Backtick to open followed by an "r"" and one to close `` `r
1+1` `` in the output.


## Hands-on!
```{r folder setup, echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE, eval=TRUE}
cwd <- getwd() 
setwd("~/Desktop/sandbox/IDBMarch2018/3-Rep-workflow")

library(googlesheets)
suppressMessages(library(tidyverse))
token <- gs_auth()
saveRDS(token, file = "googlesheets_token.rds")
suppressMessages(gs_auth(token = "googlesheets_token.rds", verbose = FALSE))


if ( c("UG_anchoring") %in% dir() ) {
  unlink("UG_anchoring", recursive = TRUE)
}

dir.create("UG_anchoring")

setwd("UG_anchoring")
dir.create("rawdata")
dir.create("data")
dir.create("documentation")
dir.create("output")
dir.create("paper")
dir.create("scripts")

#readme_file <- file.path("README.md")
writeLines("# Little Experiment", "README.md")

aux.1 <- gs_title("Quick survey")
df <- gs_read(aux.1)
write_csv(df, path = "rawdata/raw_data.csv")

#upload  

setwd(cwd)
rm(token)
unlink("googlesheets_token.rds", recursive = TRUE)

#id <- fs_create("Little Experiment", "test data")
#fs_upload(id, "rawdata/raw_data.csv")

```



```{r consort diagram, echo=FALSE}

#download.file("https://ndownloader.figshare.com/files/10553269",
#              "raw_data.csv")

df <- read_csv(file = "UG_anchoring/rawdata/raw_data.csv")
# create treatment var
df$treatment <- as.integer(df$`ID number`<=500)

table(df$treatment)
# Define outcome

# handle missing and outliers

# Balance tables (cobalt)

# Estimate effect 
lm(`Dollar value to question #1`~ `treatment`, data=df)


#install.packages("DiagrammeRsvg")
# this codes comes from:
# https://scriptsandstatistics.wordpress.com/2017/12/22/how-to-draw-a-consort-flow-diagram-using-r-and-graphviz/
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(webshot)

# webshot::install_phantomjs()


# Values ------------------------------------------------------------------
values <- c(210, 10, 200, 100, 100, 10, 10, 90, 90)
 
# Defining Text Labels ----------------------------------------------------
text <- c('Assessment for\neligibility',
          'Excluded',
          'Randomized',
          'Allocated to\nintervention',
          'Allocated to\nintervention',
          'Lost to follow-up',
          'Lost to follow-up',
          'Analysed',
          'Analysed')
 
# Defining Function -------------------------------------------------------
paste1 <- function(x, y){
  paste0(x, ' (n=', y, ')')
}
 
# Concatenating Values and Text Labels ------------------------------------
LABS <- paste1(text, values)


ndf <-
  create_node_df(
    n = 21,
    label = c('Enrollment', 'Allocation', 'Follow-Up', 'Analysis',
              LABS, rep("", 8)),
    style = c(rep("solid", 13), rep('invis', 8)),
    shape = c(rep("plaintext", 4), 
              rep("box", 9),
              rep("point", 8)),
    width = c(rep(2, 4), rep(2.5, 9), rep(0.001, 8)),
    hight = c(rep(0.5, 13), rep(0.001, 8)),
    fontsize = c(rep(14, 4), rep(10, 17)),
    fontname = c(rep('Arial Rounded MT Bold', 4), rep('Courier New', 17)),
    penwidth = 2.0,
    fixedsize = "true")

edf <-
  create_edge_df(
    arrowhead = c(rep('none', 3), rep("vee", 3), rep('none', 2), "vee", rep('none', 6),
                  rep("vee", 3), rep("none", 3), "vee", rep("none", 10)),
    color = c(rep('#00000000', 3), rep('black', 6), rep('#00000000', 6),
              rep('black', 3), rep('#00000000', 3), rep('black', 1),
              rep('#00000000', 2), rep('black', 2), 
              rep('#00000000', 6)),
    constraint = c(rep("true", 18), rep('false', 14)),
    from = c(1, 19, 20, 16, 8, 10, # column 1
             5, 14, 7, 15, 2, 3, # column 2
             18, 6, 21, 17, 9, 11, # column 3
             1, 5, # row 1
             19, 14, # row 2
             20, 7, # row 3
             16, 15, # row 4
             8, 2, # row 5
             10, 3, # row 6
             12, 4), # row 7
    to = c(19, 20, 16, 8, 10, 12, # column 1
           14, 7, 15, 2, 3, 4, # column 2
           6, 21, 17, 9, 11, 13, # column 3
           5, 18, # row 1
           14, 6, # row 2
           7, 21, # row 3
           15, 17, # row 4
           2, 9, # row 5
           3, 11, # row 6
           4, 13)) # row 7

# Create Graph ------------------------------------------------------------
g <- create_graph(ndf, 
                  edf,
                  attr_theme = NULL)
 

```
## CONSORT diagram of our little experiment
```{r, echo=FALSE}
# Plotting ----------------------------------------------------------------
render_graph(g)

```

## Balance of covariates 

## Estimated effect

## The Stata version of all of the above: 


## Additional Resources
### Garret, Ted and Jeremy's book
### The Practice of Reproducible Research   
### Code and Data for the Social Sciences  
### The Workflow of Data Analysis Using Stata  
### Reproducible Research with R and R Studio  
### Project TIER

