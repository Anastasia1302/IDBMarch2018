---
title: "Reproducible Workflow: Coding Strategies and Software [75mins]"
subtitle: "Introduction, Hands-on with Version Control (Github) and Dynamic Documents (RMarkdown)"  
author: "| Fernando Hoces de la Guardia\n| BITSS   \n| -\n| Slides at <https://goo.gl/aBQ3LR>\n"
date: "Inter-American Development Bank Workshop, March 2018"
output: 
  beamer_presentation:
    slide_level: 2
editor_options: 
  chunk_output_type: console
---


# Version Control +  DD [30/35 mins]

## Version Control Problem to avoid [15]
![http://www.phdcomics.com/comics/archive/phd101212s.gif](http://www.phdcomics.com/comics/archive/phd101212s.gif)

## Managing expectations
![Git xkcd comic](https://imgs.xkcd.com/comics/git.png)


# Dynamic Documents [20 mins]



## Dynamic Documents For Computational Reproducibility
- Based on principles of *literate programming* aims at combining code and paper in one single document 
- Best framework to achieve the holy grail of **one-click reproducible workflow**
- Best two current implementations: `RMarkdown (R)` & `Jupyter (Python)`. `Stata` is catching up (more at the end)

## Currently code and narrative components live in separate universes 
![](./Two universes.png)   


## Dynamic Documents: integrate the two universes!  
![](./One universe.png)

  
## Dynamic Documents: A Recipe  

- 1 simple language that can combine text and code: `Markdown` 
- 1 statistical package to do the analysis (`R`, `Python`, `3S's?`)
- 1 machinery to combine analysis and text to create a single output: `Pandoc`
- [Optional-but-not-really] 1 program to bring all the elements together: RStudio/RMarkdown, Jupyter

<!--
## Markdown laguange/syntax in 60 seconds
![](./RStudioCS.png)

# One Type of Dynamic Document: R Markdown

## For our excercise: R Markdown  

- `R`: **open source** programming language design for statistical analysis.   
- RStudio: free software that provides and Integrated Development Environment (IDE)  
- RStudio combines all together: R + Markdown + Pandoc to produce multiple outputs
![](http://rmarkdown.rstudio.com/images/RMarkdownFlow.png)  


## R Markdown  
![](http://rmarkdown.rstudio.com/images/RMarkdownOutputFormats.png)

## Basic Structure

- A header
- Text
- Code: inline and chunks

## Basic Structure: Header



```{r smpl yml, eval=FALSE, echo=TRUE}
---
title: "Sample Paper"
author: "Fernando Hoces de la Guardia"
output: html_document
---
```  




## Basic Structure: Body of Text

```{r smpl_yml1, eval=FALSE, echo=TRUE}
---
header
---
```

This is where you write your paper. Nothing much to add. You can check Markdown [syntax here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf). And it can use can type equations using LaTex syntax!

## Basic Structure: Code Chunks and Inline

```{r smpl_yml2, eval=FALSE, echo=TRUE}
---
header
---
```

Body of text. 


To begin a piece of code ("code chunk"). Enclose them in the following expression (Ctrl/Cmd + shift/optn + i) 

````
```{r, eval=TRUE}`r ''`
here goes the code
```
````

To write inline use only one Backtick to open followed by an "r"" and one to close `` `r
1+1` `` in the output.
--> 

## Hands-on!
```{r folder setup, echo=FALSE, eval=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
cwd <- getwd() 
setwd("~/Desktop/sandbox/IDBMarch2018/3-Rep-workflow")

library(googlesheets)
suppressMessages(library(tidyverse))
token <- gs_auth()
saveRDS(token, file = "googlesheets_token.rds")
suppressMessages(gs_auth(token = "googlesheets_token.rds", verbose = FALSE))


if ( c("UG_anchoring") %in% dir() ) {
  unlink("UG_anchoring", recursive = TRUE)
}

dir.create("UG_anchoring")

setwd("UG_anchoring")
dir.create("rawdata")
dir.create("data")
dir.create("documentation")
dir.create("output")
dir.create("paper")
dir.create("scripts")

#readme_file <- file.path("README.md")
writeLines("# Little Experiment", "README.md")

aux.1 <- gs_title("Quick survey")
df <- gs_read(aux.1)
write_csv(df, path = "rawdata/raw_data.csv")

#upload  

setwd(cwd)
rm(token)
unlink("googlesheets_token.rds", recursive = TRUE)

#id <- fs_create("Little Experiment", "test data")
#fs_upload(id, "rawdata/raw_data.csv")

```



```{r consort diagram, echo=FALSE, eval=FALSE}

#download.file("https://ndownloader.figshare.com/files/10553269",
#              "raw_data.csv")
setwd("~/Desktop/sandbox/IDBMarch2018/3-Rep-workflow")

df <- read_csv(file = "UG_anchoring/rawdata/raw_data.csv")
# create treatment var
df <- df %>% mutate("treatment" = 
                      ifelse(`ID number` >= 950 & `ID number` <= 1000,1,NA)) %>% 
  mutate("treatment" = replace(treatment, `ID number` >= 10 & `ID number` <= 50, 0) )
# create a treatment var that treats out of range values as indicators of how the number
# was read, and defines treatment for any value above 500, and control otherwise
df <- df %>% mutate("treatment_generous" = 
                      ifelse(`ID number` >= 500,1,0))

with(df, table(treatment, treatment_generous, useNA = "ifany"))


# Define outcome AQUI VOY
# Three sensible ways to define outcome:
# (1) answer to Q1 in levels, (2) answer to Q2 en levels, 
# (3) weighted average of Q1 and Q2 as fractions

df <- df %>% mutate("outcome_1" = `Dollar value to question #1`,
                    "outcome_2" = `Dollar value to question #2`) %>%
  rowwise() %>%
             mutate("outcome_3" = mean(c(outcome_1 / 1000, outcome_2 / 10),
                            na.rm = TRUE))
# handle missing and outliers
# 1 -  Values out of range: 
# Outcome and treatment variables: if close to plausible, then top code (<20% off). 
df <- df %>% mutate("treatment" = 
                      replace(treatment, 
                              `ID number` >= 0.8*950 & `ID number` <= 1.2*1000, 1), 
                    "treatment" = 
                      replace(treatment, 
                              `ID number` >= 0.8*10 & `ID number` <= 1.2*50, 0) , 
                    "outcome_1" = 
                      replace(outcome_1, 
                              outcome_1 > 1000 & outcome_1 <= 1.2*1000, 1000),
                    "outcome_2" = 
                      replace(outcome_2, 
                              outcome_2 > 10 & outcome_2 <= 1.2*10, 10),
                    "outcome_3" = 
                      replace(outcome_3, 
                              outcome_3 > 1 & outcome_3 <= 1.2*1, 1)
                    )
library(lubridate)
# Will exclude any observation that responded before begining the seminar, or after. 
seminar_begins <- Sys.time()
mdy_hms(df$Timestamp) - seminar_begins
# Missing values will be coded as NA
# Missing in either outcome or treatment var -> excluded variable
# Missing in covariates will be exlcuded of their corresponging analysis but keep for unconditional analysis. 
# There will be no additional treatment of outliers

# Balance tables t.test(asd~treatment_generous, data = df, var.equal = T)
# row 1 intercept (mean for control group)
# col 1 estimates AQUI VOY
covariates <- c("name1", "name2")
balance.table <- data.frame(row.names = covariates, 
                            "mean_control" = rep(NA,length(covariates)), 
                            "diff" = rep(NA,length(covariates)), 
                            "sd" = rep(NA,length(covariates)))
aux.2 <- summary(lm(asd~treatment_generous, data = df))$coefficients[, 1:2]

# Estimate effect 
lm(outcome_1 ~ treatment, data=df)
lm(outcome_1 ~ treatment_generous, data=df)

# Estimate effect with covariates

# Repeat excluding late responders

# Repeat excluding outliers


#install.packages("DiagrammeRsvg")
# this codes comes from:
# https://scriptsandstatistics.wordpress.com/2017/12/22/how-to-draw-a-consort-flow-diagram-using-r-and-graphviz/
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(webshot)

# webshot::install_phantomjs()


# Values ------------------------------------------------------------------
values <- c(210, 10, 200, 100, 100, 10, 10, 90, 90)
 
# Defining Text Labels ----------------------------------------------------
text <- c('Assessment for\neligibility',
          'Excluded',
          'Randomized',
          'Allocated to\nintervention',
          'Allocated to\nintervention',
          'Lost to follow-up',
          'Lost to follow-up',
          'Analysed',
          'Analysed')
 
# Defining Function -------------------------------------------------------
paste1 <- function(x, y){
  paste0(x, ' (n=', y, ')')
}
 
# Concatenating Values and Text Labels ------------------------------------
LABS <- paste1(text, values)


ndf <-
  create_node_df(
    n = 21,
    label = c('Enrollment', 'Allocation', 'Follow-Up', 'Analysis',
              LABS, rep("", 8)),
    style = c(rep("solid", 13), rep('invis', 8)),
    shape = c(rep("plaintext", 4), 
              rep("box", 9),
              rep("point", 8)),
    width = c(rep(2, 4), rep(2.5, 9), rep(0.001, 8)),
    hight = c(rep(0.5, 13), rep(0.001, 8)),
    fontsize = c(rep(14, 4), rep(10, 17)),
    fontname = c(rep('Arial Rounded MT Bold', 4), rep('Courier New', 17)),
    penwidth = 2.0,
    fixedsize = "true")

edf <-
  create_edge_df(
    arrowhead = c(rep('none', 3), rep("vee", 3), rep('none', 2), "vee", rep('none', 6),
                  rep("vee", 3), rep("none", 3), "vee", rep("none", 10)),
    color = c(rep('#00000000', 3), rep('black', 6), rep('#00000000', 6),
              rep('black', 3), rep('#00000000', 3), rep('black', 1),
              rep('#00000000', 2), rep('black', 2), 
              rep('#00000000', 6)),
    constraint = c(rep("true", 18), rep('false', 14)),
    from = c(1, 19, 20, 16, 8, 10, # column 1
             5, 14, 7, 15, 2, 3, # column 2
             18, 6, 21, 17, 9, 11, # column 3
             1, 5, # row 1
             19, 14, # row 2
             20, 7, # row 3
             16, 15, # row 4
             8, 2, # row 5
             10, 3, # row 6
             12, 4), # row 7
    to = c(19, 20, 16, 8, 10, 12, # column 1
           14, 7, 15, 2, 3, 4, # column 2
           6, 21, 17, 9, 11, 13, # column 3
           5, 18, # row 1
           14, 6, # row 2
           7, 21, # row 3
           15, 17, # row 4
           2, 9, # row 5
           3, 11, # row 6
           4, 13)) # row 7

# Create Graph ------------------------------------------------------------
g <- create_graph(ndf, 
                  edf,
                  attr_theme = NULL)
 

```
## CONSORT diagram of our little experiment
```{r, echo=FALSE, eval=FALSE}
# Plotting ----------------------------------------------------------------
render_graph(g)

```

## Balance of covariates 

## Estimated effect

## The Stata version of all of the above: 


## Additional Resources
### Garret, Ted and Jeremy's book
### The Practice of Reproducible Research   
### Code and Data for the Social Sciences  
### The Workflow of Data Analysis Using Stata  
### Reproducible Research with R and R Studio  
### Project TIER
### Great intro to GitHub by Jenny Bryan

