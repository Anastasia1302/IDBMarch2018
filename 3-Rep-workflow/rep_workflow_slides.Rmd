---
title: "Reproducible Workflow: Software [35mins]"
subtitle: "Quick Overviews of Version Control (Github) and Dynamic Documents (RMarkdown)"  
author: "| Fernando Hoces de la Guardia\n| BITSS   \n| -\n| Slides at <https://goo.gl/aBQ3LR>\n"
date: "Inter-American Development Bank Workshop, March 2018"
output: 
  beamer_presentation:
    slide_level: 2
    toc: true
editor_options: 
  chunk_output_type: console
---


# Version Control

## Version Control Problem to avoid
![http://www.phdcomics.com/comics/archive/phd101212s.gif](http://www.phdcomics.com/comics/archive/phd101212s.gif)

## Managing expectations
![Git xkcd comic](https://imgs.xkcd.com/comics/git.png)

## The Primary Goal of Version Control (for us)

**The Goal:** keep track of any potentially meaningfull modification to your code.  (Git is also great for collaboration and exploring the work of others). 

##Strategy 1:  
1 - Agree on a naming convention with you co-authors (eg: YYYYMMDDfilename_INITALS).  
2 - Begin working from the last saved version (eg: `20180325demo_FH.do`).  
3 - At the end of the day, save on a new version (eg: `20180327demo_FH.do`).  

**Pros:** Easy adoption.   

**Cons:** Error prone, hard to document, lots of files for each document.   

##Strategy 2:  
1 - Name your file `filename` (ideally `01_filename`)  
2 - Take a snapshot of your work every time you complete relevant change (day, hour or minutes).  
3 - Update your entire working folder to the cloud.   


**Pros:** Error proof, seemless documentation, one file per document, track differences across all versions, meant to work with the cloud. 

**Cons:** Harder adoption.   

## Tips to ease the adoption: concepts. 
- **Git** is the software that does all the magic. **Github** is an implementation of Git that is easier to use, provides free (public) cloud service, and tools for collaboration. 
- A repository (**repo**) is a master folder that contains all your work. 
- Whenever you take a snapshot of your *saved* work, you **commit**
- When you make changes to your files in your computer, you are working **locally**, whenever you make changes to the files in the cloud you are working **remotelly**. 
- Whenever you want to update your *remote* *repo*, you **push**. If you want to update you *local* *repo*, you **pull**.
- When you copy a repo from another person into your online github account, you **fork** it. 
- When you start a repo from github.com (just created or forked), and want to download it for the first time to your local computer, you **clone** it. 

## Tips to ease the adoption: 4 min tutorial. 
1-  Create [github.com](github.com) account and sign in. [1 min]   
2-  Search `BITSS IDB`
3-  Fork it.[1min]   
4-  (You have left the BITSS account, and are now in your account)  
5- Click on `README.md`, then click on the pencil icon [1min]
![](edit.png)  


## Tips to ease the adoption: 4 min tutorial. 
6-  Modify the title (`# IDB Reproducibility Training`) and click `Commit changes`    
7-  Go back to the root folder of the repo (`IDBMarch2018`), and click `Clone or download`. And download as a zip. 

If  you had [Github Desktop](https://desktop.github.com/) (an app from the Github company) installed, you could clone the repo and play more.   

But I just wanted to give you a quick intro to:   
 - Find code of interest, fork it, edit it, make your first commit, and download. 

## Want to learn more: 
- [Great 20 min intro to Git by Alice Bartlett](https://www.youtube.com/watch?v=eWxxfttcMts)  

- [Great 2hr tutorial to Github by Jenny Bryan (git ninja)](https://www.rstudio.com/resources/videos/happy-git-and-gihub-for-the-user-tutorial/)  

- [Documentation from Matthew Gentzkow Jesse Shapiro](http://web.stanford.edu/~gentzkow/research/CodeAndData.pdf)  

- Come to 3-Day trainning (RT2) in Seattle ([Amsterdam next week](https://www.bitss.org/events/research-transparency-and-reproducibility-training-rt2-amsterdam/), [repo from last year](https://github.com/BITSS/RT2Berkeley2017))!


# Dynamic Documents

## Dynamic Documents For Computational Reproducibility
- Based on principles of *literate programming* aims at combining code and paper in one single document 
- Best framework to achieve the holy grail of **one-click reproducible workflow**
- Best two current implementations: `RMarkdown (R)` & `Jupyter (Python)`. `Stata` is catching up (dyndocs release [here](https://www.stata.com/new-in-stata/markdown/) and reviews [here](http://data.princeton.edu/stata/markdown/markstat.htm) and [here](https://www.bitss.org/2017/09/05/review-of-statas-dyndoc/))

## Currently code and narrative components live in separate universes 
![](./Two universes.png)   


## Dynamic Documents: integrate the two universes!  
![](./One universe.png)

  
## Dynamic Documents: A Recipe  

- 1 simple language that can combine text and code: `Markdown` 
- 1 statistical package to do the analysis (`R`, `Python`, `3S's?`)
- 1 machinery to combine analysis and text to create a single output: `Pandoc`
- [Optional-but-not-really] 1 program to bring all the elements together: RStudio/RMarkdown, Jupyter

## Basic Structure: Code Chunks and Inline

```{r smpl_yml3, eval=FALSE, echo=TRUE}
---
header
---
```

Body of text. 


To begin a piece of code ("code chunk"). Enclose them in the following expression (Ctrl/Cmd + shift/optn + i) 

````
```{r, eval=TRUE}`r ''`
here goes the code
```
````

To write inline use only one Backtick to open followed by an "r"" and one to close `` `r
1+1` `` in the output.
<!--
## Markdown laguange/syntax in 60 seconds
![](./RStudioCS.png)

# One Type of Dynamic Document: R Markdown

## For our excercise: R Markdown  

- `R`: **open source** programming language design for statistical analysis.   
- RStudio: free software that provides and Integrated Development Environment (IDE)  
- RStudio combines all together: R + Markdown + Pandoc to produce multiple outputs
![](http://rmarkdown.rstudio.com/images/RMarkdownFlow.png)  


## R Markdown  
![](http://rmarkdown.rstudio.com/images/RMarkdownOutputFormats.png)

## Basic Structure

- A header
- Text
- Code: inline and chunks

## Basic Structure: Header



```{r smpl yml, eval=FALSE, echo=TRUE}
---
title: "Sample Paper"
author: "Fernando Hoces de la Guardia"
output: html_document
---
```  




## Basic Structure: Body of Text

```{r smpl_yml1, eval=FALSE, echo=TRUE}
---
header
---
```

This is where you write your paper. Nothing much to add. You can check Markdown [syntax here](https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf). And it can use can type equations using LaTex syntax!

## Basic Structure: Code Chunks and Inline

```{r smpl_yml2, eval=FALSE, echo=TRUE}
---
header
---
```

Body of text. 


To begin a piece of code ("code chunk"). Enclose them in the following expression (Ctrl/Cmd + shift/optn + i) 

````
```{r, eval=TRUE}`r ''`
here goes the code
```
````

To write inline use only one Backtick to open followed by an "r"" and one to close `` `r
1+1` `` in the output.
--> 


<!--
## Super short demo
```{r folder setup, echo=FALSE, eval=FALSE, warning=FALSE, message=FALSE, eval=FALSE}
cwd <- getwd() 
setwd("~/Desktop/sandbox/IDBMarch2018/3-Rep-workflow")

library(googlesheets)
suppressMessages(library(tidyverse))
token <- gs_auth()
saveRDS(token, file = "googlesheets_token.rds")
suppressMessages(gs_auth(token = "googlesheets_token.rds", verbose = FALSE))


if ( c("UG_anchoring") %in% dir() ) {
  unlink("UG_anchoring", recursive = TRUE)
}

dir.create("UG_anchoring")

setwd("UG_anchoring")
dir.create("rawdata")
dir.create("data")
dir.create("documentation")
dir.create("output")
dir.create("paper")
dir.create("scripts")

#readme_file <- file.path("README.md")
writeLines("# Little Experiment", "README.md")

aux.1 <- gs_title("Quick survey")
df <- gs_read(aux.1)
write_csv(df, path = "rawdata/raw_data.csv")

#upload  

setwd(cwd)
rm(token)
unlink("googlesheets_token.rds", recursive = TRUE)

#id <- fs_create("Little Experiment", "test data")
#fs_upload(id, "rawdata/raw_data.csv")

```

## If I have time, show analysis of experiments. 
- OLS: output 1, ouput 2, combination.  
- No controls, permutation of controls.   
- Different data cleaning.   

## If no time, then go with Birthday problem example: 


```{r consort diagram, echo=FALSE, eval=FALSE}

#download.file("https://ndownloader.figshare.com/files/10553269",
#              "raw_data.csv")
setwd("~/Desktop/sandbox/IDBMarch2018/3-Rep-workflow")

df <- read_csv(file = "UG_anchoring/rawdata/raw_data.csv")
# create treatment var
df <- df %>% mutate("treatment" = 
                      ifelse(`ID number` >= 950 & `ID number` <= 1000,1,NA)) %>% 
  mutate("treatment" = replace(treatment, `ID number` >= 10 & `ID number` <= 50, 0) )
# create a treatment var that treats out of range values as indicators of how the number
# was read, and defines treatment for any value above 500, and control otherwise
df <- df %>% mutate("treatment_generous" = 
                      ifelse(`ID number` >= 500,1,0))

with(df, table(treatment, treatment_generous, useNA = "ifany"))


# Define outcome AQUI VOY
# Three sensible ways to define outcome:
# (1) answer to Q1 in levels, (2) answer to Q2 en levels, 
# (3) weighted average of Q1 and Q2 as fractions

df <- df %>% mutate("outcome_1" = `Dollar value to question #1`,
                    "outcome_2" = `Dollar value to question #2`) %>%
  rowwise() %>%
             mutate("outcome_3" = mean(c(outcome_1 / 1000, outcome_2 / 10),
                            na.rm = TRUE))
# handle missing and outliers
# 1 -  Values out of range: 
# Outcome and treatment variables: if close to plausible, then top code (<20% off). 
df <- df %>% mutate("treatment" = 
                      replace(treatment, 
                              `ID number` >= 0.8*950 & `ID number` <= 1.2*1000, 1), 
                    "treatment" = 
                      replace(treatment, 
                              `ID number` >= 0.8*10 & `ID number` <= 1.2*50, 0) , 
                    "outcome_1" = 
                      replace(outcome_1, 
                              outcome_1 > 1000 & outcome_1 <= 1.2*1000, 1000),
                    "outcome_2" = 
                      replace(outcome_2, 
                              outcome_2 > 10 & outcome_2 <= 1.2*10, 10),
                    "outcome_3" = 
                      replace(outcome_3, 
                              outcome_3 > 1 & outcome_3 <= 1.2*1, 1)
                    )
library(lubridate)
# Will exclude any observation that responded before begining the seminar, or after. 
seminar_begins <- Sys.time()
mdy_hms(df$Timestamp) - seminar_begins
# Missing values will be coded as NA
# Missing in either outcome or treatment var -> excluded variable
# Missing in covariates will be exlcuded of their corresponging analysis but keep for unconditional analysis. 
# There will be no additional treatment of outliers

# Balance tables t.test(asd~treatment_generous, data = df, var.equal = T)
# row 1 intercept (mean for control group)
# col 1 estimates AQUI VOY
covariates <- c("name1", "name2")
balance.table <- data.frame(row.names = covariates, 
                            "mean_control" = rep(NA,length(covariates)), 
                            "diff" = rep(NA,length(covariates)), 
                            "sd" = rep(NA,length(covariates)))
aux.2 <- summary(lm(asd~treatment_generous, data = df))$coefficients[, 1:2]

# Estimate effect 
lm(outcome_1 ~ treatment, data=df)
lm(outcome_1 ~ treatment_generous, data=df)

# Estimate effect with covariates

# Repeat excluding late responders

# Repeat excluding outliers


#install.packages("DiagrammeRsvg")
# this codes comes from:
# https://scriptsandstatistics.wordpress.com/2017/12/22/how-to-draw-a-consort-flow-diagram-using-r-and-graphviz/
library(DiagrammeR)
library(DiagrammeRsvg)
library(rsvg)
library(webshot)

# webshot::install_phantomjs()


# Values ------------------------------------------------------------------
values <- c(210, 10, 200, 100, 100, 10, 10, 90, 90)
 
# Defining Text Labels ----------------------------------------------------
text <- c('Assessment for\neligibility',
          'Excluded',
          'Randomized',
          'Allocated to\nintervention',
          'Allocated to\nintervention',
          'Lost to follow-up',
          'Lost to follow-up',
          'Analysed',
          'Analysed')
 
# Defining Function -------------------------------------------------------
paste1 <- function(x, y){
  paste0(x, ' (n=', y, ')')
}
 
# Concatenating Values and Text Labels ------------------------------------
LABS <- paste1(text, values)


ndf <-
  create_node_df(
    n = 21,
    label = c('Enrollment', 'Allocation', 'Follow-Up', 'Analysis',
              LABS, rep("", 8)),
    style = c(rep("solid", 13), rep('invis', 8)),
    shape = c(rep("plaintext", 4), 
              rep("box", 9),
              rep("point", 8)),
    width = c(rep(2, 4), rep(2.5, 9), rep(0.001, 8)),
    hight = c(rep(0.5, 13), rep(0.001, 8)),
    fontsize = c(rep(14, 4), rep(10, 17)),
    fontname = c(rep('Arial Rounded MT Bold', 4), rep('Courier New', 17)),
    penwidth = 2.0,
    fixedsize = "true")

edf <-
  create_edge_df(
    arrowhead = c(rep('none', 3), rep("vee", 3), rep('none', 2), "vee", rep('none', 6),
                  rep("vee", 3), rep("none", 3), "vee", rep("none", 10)),
    color = c(rep('#00000000', 3), rep('black', 6), rep('#00000000', 6),
              rep('black', 3), rep('#00000000', 3), rep('black', 1),
              rep('#00000000', 2), rep('black', 2), 
              rep('#00000000', 6)),
    constraint = c(rep("true", 18), rep('false', 14)),
    from = c(1, 19, 20, 16, 8, 10, # column 1
             5, 14, 7, 15, 2, 3, # column 2
             18, 6, 21, 17, 9, 11, # column 3
             1, 5, # row 1
             19, 14, # row 2
             20, 7, # row 3
             16, 15, # row 4
             8, 2, # row 5
             10, 3, # row 6
             12, 4), # row 7
    to = c(19, 20, 16, 8, 10, 12, # column 1
           14, 7, 15, 2, 3, 4, # column 2
           6, 21, 17, 9, 11, 13, # column 3
           5, 18, # row 1
           14, 6, # row 2
           7, 21, # row 3
           15, 17, # row 4
           2, 9, # row 5
           3, 11, # row 6
           4, 13)) # row 7

# Create Graph ------------------------------------------------------------
g <- create_graph(ndf, 
                  edf,
                  attr_theme = NULL)
 

```
## CONSORT diagram of our little experiment
```{r, echo=FALSE, eval=FALSE}
# Plotting ----------------------------------------------------------------
render_graph(g)

```

-->


## Hands-on excercise: the birthday problem!
```{r global pars, eval=TRUE, echo=FALSE, results='hide'}
n.pers = 20
set.seed(1234)
```  
As an illustration lets write a report using the participants in this workshop to illustrate the famous [birthday problem](https://en.wikipedia.org/wiki/Birthday_problem). 

>What is the probability that at least two people this room share the same birthday?

>Is it something like $\frac{1}{365} \times N =$   `r round(1/365 * n.pers, 3)`?

## Create a new RMarkdown File

1 - In RStudio: `File-> New File -> RMarkdown...`  
2 - Name it, and save it.   
3 - Review/edit the header, and delete all the default body of text except for one code chunk.   
4 - Define a seed (`set.seed(1234)` and number of people in the room (`n.pers = ?`)

## The birthday problem: the math
Actually the math says otherwise: 
\begin{align} 
 1 - \bar p(n) &= 1 \times \left(1-\frac{1}{365}\right) \times \left(1-\frac{2}{365}\right) \times \cdots \times \left(1-\frac{n-1}{365}\right) \nonumber  \\  &= \frac{ 365 \times 364 \times \cdots \times (365-n+1) }{ 365^n } \nonumber \\ &= \frac{ 365! }{ 365^n (365-n)!} = \frac{n!\cdot\binom{365}{n}}{365^n}\\
p(n= `r n.pers`) &= `r  round(1 - factorial(n.pers) * choose(365,n.pers)/ 365^n.pers, 3)`  \nonumber
\end{align}

## Code for the math (<https://goo.gl/ZFQvba>)

Don't look at this: just copy and paste into your report
```{r math, eval=FALSE}
\begin{align} 
 1 - \bar p(n) &= 1 \times \left(1-\frac{1}{365}\right) 
 \times \left(1-\frac{2}{365}\right) \times \cdots \times 
 \left(1-\frac{n-1}{365}\right) \nonumber  \\  
 &= \frac{ 365 \times 364 \times \cdots \times 
   (365-n+1) }{ 365^n } \nonumber \\ 
 &= \frac{ 365! }{ 365^n (365-n)!} = 
   \frac{n!\cdot\binom{365}{n}}{365^n}\\
p(n= `r n.pers`) &= `r  
 round(1 - factorial(n.pers) * 
         choose(365,n.pers)/ 365^n.pers, 3)`\nonumber
\end{align}
```

## Don't like math? Let's run a simple simulation!   
 1 - Simulate 10,000 rooms with $n = `r n.pers`$ random birthdays, and store the results in matrix where each row represents a room.   
 2 - For each room (row) compute the number of unique birthdays.   
 3 - Compute the average number of times a room has `r n.pers` unique birthdays, across 10,000 simulations, and report the complement.    


## Code for the simulation (<https://goo.gl/ZFQvba>)  

```{r birthday prob, eval=TRUE, echo=TRUE}
birthday.prob = function(n.pers, n.sims) {
  # simulate birthdays
  birthdays = matrix(round(runif(n.pers * n.sims, 1, 365)), 
                      nrow = n.sims, ncol = n.pers)
  # for each room (row) get unique birthdays
  unique.birthdays = apply(birthdays, 1, unique)
  # Indicator with 1 if all are unique birthdays
  all.different = (lapply(unique.birthdays, length) == n.pers)
  # Compute average time all have different birthdays 
  result = 1 - mean(all.different)
return(result)
}
n.pers.param = 20
n.sims.param = 1e4
birthday.prob(n.pers.param,n.sims.param)
```

## Results   
- Many people originally think of a prob ~ $\frac{1}{365} \times N =$   `r round(1/365 * n.pers.param, 3)`
- However the true probability is of $p(n= `r n.pers.param`) = `r round(1 - factorial(n.pers.param) * choose(365,n.pers.param)/ 365^n.pers.param, 3)`$
- And the simulated probability is of  `r birthday.prob(n.pers = n.pers.param, n.sims = n.sims.param)`

## Final Remarks & More Resources
 - With DD with can achieve a one-click reproducible workflow.
 - This is particularly helpful to understand/present results that are hard to digest.
 - Stata just develop an internal version of DD for v15. [Review Here](https://www.bitss.org/2017/09/05/review-of-statas-dyndoc/)
 - More great examples [here](https://github.com/BITSS/Annual2017/tree/master/3-Rmarkdown)
 - Want to learn more: [great free books](https://bookdown.org/) (can you guess how they were written?)

## Bonus let's try and excercise in Stata (15) 
1- Go to github.com and search `dyndoc tier` or click here: [github.com/dvorakt/TIER_exercises](https://github.com/dvorakt/TIER_exercises).   
2- Download or clone the repo.   
3- Unzip it.   
4- Open Stata (15) and type `dyndoc filepath/dyndoc_debt_growth/debt and growth stata dyndoc.do", replace`
5- Go to the folder and click in `debt and growth stata dyndoc.html` 


